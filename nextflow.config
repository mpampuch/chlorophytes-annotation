/*
========================================================================================
    Nextflow Configuration File
========================================================================================
    Configuration for Nanopore vs Illumina Quality Assessment Pipeline
========================================================================================
*/

// Global default params, used in configs
params {
    // Input/output options
    illumina_reads         = null
    nanopore_reads         = null
    outdir                 = 'results'
    
    // Analysis parameters
    threads                = 4
    kmer_size              = 31
    bloom_bits             = 37
    
    // Utility options
    help                   = false
    version                = false
    
    // Resource requirements
    max_memory             = '32.GB'
    max_cpus               = 8
    max_time               = '48.h'
}

// Process configurations
process {
    // Global process configuration
    shell = ['/bin/bash', '-euo', 'pipefail']
    
    // Default resource requirements
    cpus   = { check_max( 2 * task.attempt, 'cpus' ) }
    memory = { check_max( 4.GB * task.attempt, 'memory' ) }
    time   = { check_max( 2.h * task.attempt, 'time' ) }
    
    // Error handling
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 1
    maxErrors     = '-1'
    
    // Process-specific configurations
    withName: CHECK_YAK {
        cpus   = 1
        memory = 1.GB
        time   = 10.m
    }
    
    withName: COUNT_ILLUMINA_KMERS {
        cpus   = { check_max( params.threads, 'cpus' ) }
        memory = { check_max( 16.GB * task.attempt, 'memory' ) }
        time   = { check_max( 4.h * task.attempt, 'time' ) }
    }
    
    withName: COUNT_NANOPORE_KMERS {
        cpus   = { check_max( params.threads, 'cpus' ) }
        memory = { check_max( 8.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h * task.attempt, 'time' ) }
    }
    
    withName: COMPARE_KMER_SPECTRA {
        cpus   = 2
        memory = { check_max( 4.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h * task.attempt, 'time' ) }
    }
    
    withName: COMPUTE_READ_QUALITY {
        cpus   = { check_max( params.threads, 'cpus' ) }
        memory = { check_max( 12.GB * task.attempt, 'memory' ) }
        time   = { check_max( 3.h * task.attempt, 'time' ) }
    }
    
    withName: GENERATE_SUMMARY_REPORT {
        cpus   = 1
        memory = 2.GB
        time   = 30.m
    }
}

// Execution profiles
profiles {
    conda {
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        // Note: yak needs to be installed separately as it's not available in conda
    }
    
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        // Note: Custom container needed with yak installed
    }
    
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        // Note: Custom container needed with yak installed
    }
    
    local {
        // Local execution profile - assumes yak is installed locally
        process.executor = 'local'
    }
    
    slurm {
        process.executor       = 'slurm'
        process.queue          = 'normal'
        process.clusterOptions = '--qos=normal'
    }
    
    test {
        // Test profile with minimal resources
        params.max_cpus        = 2
        params.max_memory      = '4.GB'
        params.max_time        = '1.h'
    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Increase time available to build Conda environment
conda { createTimeout = "120 min" }

// Load modules.config if available
try {
    includeConfig 'conf/modules.config'
} catch (Exception e) {
    System.err.println("WARNING: Could not load modules config: " + e.message);
}

// Function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}